[elasticsearch]
  url = "http://localhost:9202"

  # Timeout in milliseconds on client calls to Elasticsearch.
  timeout = 10000

  # Constraint on the version of Elasticsearch.
  version_req = ">=7.13.0"

  # Number of documents loaded per request when performing a `list_documents`
  scroll_chunk_size = 100

  # Liveness of the PIT while performing a `list_documents`.
  scroll_pit_alive = "1m"

  # Max of concurrent requests during insertion.
  insertion_concurrent_requests = 8

  # Number of document per request during insertion.
  insertion_chunk_size = 100

  # Number of shards copies that must be active before performing indexing
  # operations.
  wait_for_active_shards = 1

[elasticsearch.force_merge]
  # If this is set to `true` a force merge will be performed after an index
  # is published. For more details see
  # https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-forcemerge.html
  enabled = true

  # Timeout in milliseconds for the forcemerge operation
  timeout = 10_000 # 10s

  # Allow the forcemerge query to timeout, which would only result in a
  # warning. Note that the forcemerge operation will still continue to be
  # performed in the background anyway.
  allow_timeout = true

  # Number of segments to merge to.
  max_number_segments = 1

  # Force refresh before force_merge
  refresh = true

# Setup a backoff to wait after a bulk operation fail and retry the operation,
# each successive retry will wait twice as long as the previous one.
[elasticsearch.bulk_backoff]
  # Number of retries after the first failure (set 0 to never retry)
  retry = 6

  # Waiting time in milliseconds after the first failure
  wait = 1000
